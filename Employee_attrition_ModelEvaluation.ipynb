{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('employee_data_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Attrition_Yes</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_Research scntist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>JobRole_mgr</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>OverTime_No</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>IsMale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.909807</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.923407</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.350036</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.646385</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.799571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.382248</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.626342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.568361</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.479599</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeNumber  Attrition_Yes       Age  DailyRate  DistanceFromHome  \\\n",
       "0                  1              1  0.547619   0.715820          0.000000   \n",
       "1                  4              1  0.452381   0.909807          0.035714   \n",
       "2                  5              0  0.357143   0.923407          0.071429   \n",
       "3                  7              0  0.214286   0.350036          0.035714   \n",
       "4                  8              0  0.333333   0.646385          0.035714   \n",
       "...              ...            ...       ...        ...               ...   \n",
       "1465            1106              1  0.166667   0.799571          0.107143   \n",
       "1466            1185              0  0.404762   0.382248          0.107143   \n",
       "1467            1196              0  0.452381   0.626342          0.000000   \n",
       "1468            1474              0  0.523810   0.568361          0.035714   \n",
       "1469            1653              0  0.166667   0.479599          0.035714   \n",
       "\n",
       "      Education  EnvironmentSatisfaction  HourlyRate  JobInvolvement  \\\n",
       "0          0.25                 0.333333    0.914286        0.666667   \n",
       "1          0.25                 1.000000    0.885714        0.333333   \n",
       "2          0.75                 1.000000    0.371429        0.666667   \n",
       "3          0.00                 0.000000    0.142857        0.666667   \n",
       "4          0.25                 1.000000    0.700000        0.666667   \n",
       "...         ...                      ...         ...             ...   \n",
       "1465       0.00                 1.000000    0.028571        0.666667   \n",
       "1466       0.75                 1.000000    0.242857        0.333333   \n",
       "1467       0.50                 1.000000    0.371429        0.333333   \n",
       "1468       0.50                 0.666667    0.542857        0.666667   \n",
       "1469       0.00                 1.000000    0.671429        1.000000   \n",
       "\n",
       "      JobLevel  ...  JobRole_Research scntist  JobRole_Sales Executive  \\\n",
       "0         0.25  ...                       0.0                      1.0   \n",
       "1         0.00  ...                       0.0                      0.0   \n",
       "2         0.00  ...                       0.0                      0.0   \n",
       "3         0.00  ...                       0.0                      0.0   \n",
       "4         0.00  ...                       0.0                      0.0   \n",
       "...        ...  ...                       ...                      ...   \n",
       "1465      0.00  ...                       0.0                      0.0   \n",
       "1466      0.00  ...                       0.0                      0.0   \n",
       "1467      0.25  ...                       0.0                      0.0   \n",
       "1468      0.00  ...                       0.0                      0.0   \n",
       "1469      0.25  ...                       0.0                      0.0   \n",
       "\n",
       "      JobRole_Sales Representative  JobRole_mgr  MaritalStatus_Divorced  \\\n",
       "0                              0.0          0.0                     0.0   \n",
       "1                              0.0          0.0                     0.0   \n",
       "2                              0.0          0.0                     0.0   \n",
       "3                              0.0          0.0                     0.0   \n",
       "4                              0.0          0.0                     0.0   \n",
       "...                            ...          ...                     ...   \n",
       "1465                           0.0          0.0                     0.0   \n",
       "1466                           0.0          0.0                     0.0   \n",
       "1467                           0.0          0.0                     0.0   \n",
       "1468                           0.0          0.0                     1.0   \n",
       "1469                           0.0          0.0                     1.0   \n",
       "\n",
       "      MaritalStatus_Married  MaritalStatus_Single  OverTime_No  OverTime_Yes  \\\n",
       "0                       0.0                   1.0          0.0           1.0   \n",
       "1                       0.0                   1.0          0.0           1.0   \n",
       "2                       1.0                   0.0          0.0           1.0   \n",
       "3                       1.0                   0.0          1.0           0.0   \n",
       "4                       0.0                   1.0          1.0           0.0   \n",
       "...                     ...                   ...          ...           ...   \n",
       "1465                    1.0                   0.0          0.0           1.0   \n",
       "1466                    1.0                   0.0          1.0           0.0   \n",
       "1467                    1.0                   0.0          1.0           0.0   \n",
       "1468                    0.0                   0.0          1.0           0.0   \n",
       "1469                    0.0                   0.0          1.0           0.0   \n",
       "\n",
       "      IsMale  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "...      ...  \n",
       "1465     1.0  \n",
       "1466     1.0  \n",
       "1467     0.0  \n",
       "1468     0.0  \n",
       "1469     0.0  \n",
       "\n",
       "[1470 rows x 57 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attrition_Yes                        1.000000\n",
       "OverTime_Yes                         0.246118\n",
       "MaritalStatus_Single                 0.175419\n",
       "JobRole_Sales Representative         0.157234\n",
       "BusinessTravel_Travel_Frequently     0.115143\n",
       "JobRole_Laboratory Technician        0.094361\n",
       "Department_Sales                     0.080855\n",
       "DistanceFromHome                     0.077924\n",
       "EducationField_Technical Degree      0.069355\n",
       "JobRole_Laboratory Tech              0.059511\n",
       "JobRole_Research scntist             0.059511\n",
       "EducationField_Marketing             0.055781\n",
       "NumCompaniesWorked                   0.043494\n",
       "EducationField_Human Resources       0.036466\n",
       "JobRole_Human Resources              0.036215\n",
       "IsMale                               0.028681\n",
       "JobRole_Sales Executive              0.019774\n",
       "Department_Human Resources           0.016832\n",
       "MonthlyRate                          0.014940\n",
       "PerformanceRating                    0.002889\n",
       "JobRole_Research Scientist          -0.004254\n",
       "HourlyRate                          -0.006846\n",
       "EmployeeNumber                      -0.010577\n",
       "JobRole_Research Dir                -0.011439\n",
       "JobRole_Manufacturing Dir           -0.011439\n",
       "PercentSalaryHike                   -0.013478\n",
       "JobRole_mgr                         -0.016182\n",
       "EducationField_Other                -0.017898\n",
       "Education                           -0.031373\n",
       "EducationField_Life Sciences        -0.032703\n",
       "YearsSinceLastPromotion             -0.033019\n",
       "RelationshipSatisfaction            -0.045872\n",
       "EducationField_Medical              -0.046999\n",
       "BusinessTravel_Travel_Rarely        -0.049538\n",
       "DailyRate                           -0.056652\n",
       "TrainingTimesLastYear               -0.059478\n",
       "WorkLifeBalance                     -0.063939\n",
       "BusinessTravel_Non-Travel           -0.074457\n",
       "JobRole_Healthcare Representative   -0.078696\n",
       "JobRole_Manager                     -0.081715\n",
       "JobRole_Manufacturing Director      -0.082247\n",
       "Department_Research & Development   -0.085293\n",
       "MaritalStatus_Divorced              -0.087716\n",
       "JobRole_Research Director           -0.088076\n",
       "MaritalStatus_Married               -0.090984\n",
       "EnvironmentSatisfaction             -0.103369\n",
       "JobSatisfaction                     -0.103481\n",
       "JobInvolvement                      -0.130016\n",
       "YearsAtCompany                      -0.134392\n",
       "StockOptionLevel                    -0.137145\n",
       "YearsWithCurrManager                -0.156199\n",
       "Age                                 -0.159205\n",
       "MonthlyIncome                       -0.159346\n",
       "YearsInCurrentRole                  -0.160545\n",
       "JobLevel                            -0.169105\n",
       "TotalWorkingYears                   -0.171063\n",
       "OverTime_No                         -0.246118\n",
       "Name: Attrition_Yes, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc['Attrition_Yes'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1233\n",
       "1     237\n",
       "Name: Attrition_Yes, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Attrition_Yes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Attrition_Yes</td>  <th>  R-squared:         </th> <td>   0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 02 Mar 2021</td> <th>  Prob (F-statistic):</th> <td>9.18e-64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:49:04</td>     <th>  Log-Likelihood:    </th> <td> -391.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1470</td>      <th>  AIC:               </th> <td>   884.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1419</td>      <th>  BIC:               </th> <td>   1154.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    50</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EmployeeNumber</th>                    <td>-5.553e-06</td> <td> 1.42e-05</td> <td>   -0.390</td> <td> 0.696</td> <td>-3.35e-05</td> <td> 2.23e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                               <td>   -0.1456</td> <td>    0.056</td> <td>   -2.612</td> <td> 0.009</td> <td>   -0.255</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DailyRate</th>                         <td>   -0.0353</td> <td>    0.030</td> <td>   -1.193</td> <td> 0.233</td> <td>   -0.093</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DistanceFromHome</th>                  <td>    0.1028</td> <td>    0.029</td> <td>    3.509</td> <td> 0.000</td> <td>    0.045</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education</th>                         <td>    0.0060</td> <td>    0.034</td> <td>    0.177</td> <td> 0.860</td> <td>   -0.061</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EnvironmentSatisfaction</th>           <td>   -0.1202</td> <td>    0.023</td> <td>   -5.137</td> <td> 0.000</td> <td>   -0.166</td> <td>   -0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HourlyRate</th>                        <td>   -0.0147</td> <td>    0.029</td> <td>   -0.501</td> <td> 0.617</td> <td>   -0.072</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobInvolvement</th>                    <td>   -0.1726</td> <td>    0.036</td> <td>   -4.805</td> <td> 0.000</td> <td>   -0.243</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobLevel</th>                          <td>   -0.0048</td> <td>    0.110</td> <td>   -0.043</td> <td> 0.966</td> <td>   -0.221</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobSatisfaction</th>                   <td>   -0.1107</td> <td>    0.023</td> <td>   -4.782</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NumCompaniesWorked</th>                <td>    0.1544</td> <td>    0.034</td> <td>    4.510</td> <td> 0.000</td> <td>    0.087</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PercentSalaryHike</th>                 <td>   -0.0320</td> <td>    0.051</td> <td>   -0.622</td> <td> 0.534</td> <td>   -0.133</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PerformanceRating</th>                 <td>    0.0202</td> <td>    0.037</td> <td>    0.545</td> <td> 0.586</td> <td>   -0.053</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RelationshipSatisfaction</th>          <td>   -0.0683</td> <td>    0.024</td> <td>   -2.881</td> <td> 0.004</td> <td>   -0.115</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>StockOptionLevel</th>                  <td>   -0.0502</td> <td>    0.041</td> <td>   -1.225</td> <td> 0.221</td> <td>   -0.130</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TotalWorkingYears</th>                 <td>   -0.1409</td> <td>    0.096</td> <td>   -1.462</td> <td> 0.144</td> <td>   -0.330</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TrainingTimesLastYear</th>             <td>   -0.0799</td> <td>    0.040</td> <td>   -2.003</td> <td> 0.045</td> <td>   -0.158</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WorkLifeBalance</th>                   <td>   -0.0919</td> <td>    0.036</td> <td>   -2.541</td> <td> 0.011</td> <td>   -0.163</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearsAtCompany</th>                    <td>    0.2214</td> <td>    0.120</td> <td>    1.848</td> <td> 0.065</td> <td>   -0.014</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearsInCurrentRole</th>                <td>   -0.1664</td> <td>    0.070</td> <td>   -2.388</td> <td> 0.017</td> <td>   -0.303</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearsSinceLastPromotion</th>           <td>    0.1627</td> <td>    0.052</td> <td>    3.157</td> <td> 0.002</td> <td>    0.062</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearsWithCurrManager</th>              <td>   -0.1631</td> <td>    0.067</td> <td>   -2.420</td> <td> 0.016</td> <td>   -0.295</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MonthlyRate</th>                       <td>    0.0105</td> <td>    0.030</td> <td>    0.354</td> <td> 0.723</td> <td>   -0.048</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MonthlyIncome</th>                     <td>   -0.0078</td> <td>    0.132</td> <td>   -0.059</td> <td> 0.953</td> <td>   -0.267</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessTravel_Non-Travel</th>         <td>    0.0644</td> <td>    0.026</td> <td>    2.436</td> <td> 0.015</td> <td>    0.013</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessTravel_Travel_Frequently</th>  <td>    0.2173</td> <td>    0.024</td> <td>    9.196</td> <td> 0.000</td> <td>    0.171</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessTravel_Travel_Rarely</th>      <td>    0.1292</td> <td>    0.020</td> <td>    6.390</td> <td> 0.000</td> <td>    0.090</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Department_Human Resources</th>        <td>    0.0577</td> <td>    0.082</td> <td>    0.700</td> <td> 0.484</td> <td>   -0.104</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Department_Research & Development</th> <td>    0.1897</td> <td>    0.047</td> <td>    4.024</td> <td> 0.000</td> <td>    0.097</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Department_Sales</th>                  <td>    0.1635</td> <td>    0.055</td> <td>    2.976</td> <td> 0.003</td> <td>    0.056</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Human Resources</th>    <td>    0.1535</td> <td>    0.070</td> <td>    2.196</td> <td> 0.028</td> <td>    0.016</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Life Sciences</th>      <td>    0.0314</td> <td>    0.022</td> <td>    1.453</td> <td> 0.146</td> <td>   -0.011</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Marketing</th>          <td>    0.0714</td> <td>    0.032</td> <td>    2.220</td> <td> 0.027</td> <td>    0.008</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Medical</th>            <td>    0.0163</td> <td>    0.023</td> <td>    0.722</td> <td> 0.471</td> <td>   -0.028</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Other</th>              <td>    0.0106</td> <td>    0.035</td> <td>    0.300</td> <td> 0.764</td> <td>   -0.059</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EducationField_Technical Degree</th>   <td>    0.1277</td> <td>    0.030</td> <td>    4.230</td> <td> 0.000</td> <td>    0.068</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Healthcare Representative</th> <td>   -0.1397</td> <td>    0.058</td> <td>   -2.408</td> <td> 0.016</td> <td>   -0.253</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Human Resources</th>           <td>    0.0789</td> <td>    0.117</td> <td>    0.676</td> <td> 0.499</td> <td>   -0.150</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Laboratory Tech</th>           <td>    0.7383</td> <td>    0.305</td> <td>    2.418</td> <td> 0.016</td> <td>    0.139</td> <td>    1.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Laboratory Technician</th>     <td>   -0.0067</td> <td>    0.058</td> <td>   -0.115</td> <td> 0.908</td> <td>   -0.120</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Manager</th>                   <td>   -0.0793</td> <td>    0.069</td> <td>   -1.141</td> <td> 0.254</td> <td>   -0.216</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Manufacturing Dir</th>         <td>   -0.0422</td> <td>    0.306</td> <td>   -0.138</td> <td> 0.891</td> <td>   -0.643</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Manufacturing Director</th>    <td>   -0.1253</td> <td>    0.058</td> <td>   -2.175</td> <td> 0.030</td> <td>   -0.238</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Research Dir</th>              <td>   -0.3121</td> <td>    0.308</td> <td>   -1.014</td> <td> 0.311</td> <td>   -0.916</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Research Director</th>         <td>   -0.1321</td> <td>    0.070</td> <td>   -1.875</td> <td> 0.061</td> <td>   -0.270</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Research Scientist</th>        <td>   -0.1043</td> <td>    0.058</td> <td>   -1.806</td> <td> 0.071</td> <td>   -0.218</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Research scntist</th>          <td>    0.5670</td> <td>    0.306</td> <td>    1.852</td> <td> 0.064</td> <td>   -0.034</td> <td>    1.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Sales Executive</th>           <td>   -0.0359</td> <td>    0.076</td> <td>   -0.474</td> <td> 0.636</td> <td>   -0.185</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_Sales Representative</th>      <td>    0.1162</td> <td>    0.084</td> <td>    1.390</td> <td> 0.165</td> <td>   -0.048</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JobRole_mgr</th>                       <td>   -0.1120</td> <td>    0.225</td> <td>   -0.499</td> <td> 0.618</td> <td>   -0.552</td> <td>    0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MaritalStatus_Divorced</th>            <td>    0.0966</td> <td>    0.025</td> <td>    3.907</td> <td> 0.000</td> <td>    0.048</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MaritalStatus_Married</th>             <td>    0.1076</td> <td>    0.021</td> <td>    5.222</td> <td> 0.000</td> <td>    0.067</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MaritalStatus_Single</th>              <td>    0.2067</td> <td>    0.023</td> <td>    8.932</td> <td> 0.000</td> <td>    0.161</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OverTime_No</th>                       <td>    0.1005</td> <td>    0.027</td> <td>    3.711</td> <td> 0.000</td> <td>    0.047</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OverTime_Yes</th>                      <td>    0.3104</td> <td>    0.027</td> <td>   11.309</td> <td> 0.000</td> <td>    0.257</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsMale</th>                            <td>    0.0328</td> <td>    0.017</td> <td>    1.890</td> <td> 0.059</td> <td>   -0.001</td> <td>    0.067</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.912</td> <th>  Durbin-Watson:     </th> <td>   1.911</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 473.229</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.278</td>  <th>  Prob(JB):          </th> <td>1.74e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.092</td>  <th>  Cond. No.          </th> <td>1.00e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.07e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Attrition_Yes   R-squared:                       0.263\n",
       "Model:                            OLS   Adj. R-squared:                  0.237\n",
       "Method:                 Least Squares   F-statistic:                     10.12\n",
       "Date:                Tue, 02 Mar 2021   Prob (F-statistic):           9.18e-64\n",
       "Time:                        22:49:04   Log-Likelihood:                -391.14\n",
       "No. Observations:                1470   AIC:                             884.3\n",
       "Df Residuals:                    1419   BIC:                             1154.\n",
       "Df Model:                          50                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "EmployeeNumber                    -5.553e-06   1.42e-05     -0.390      0.696   -3.35e-05    2.23e-05\n",
       "Age                                  -0.1456      0.056     -2.612      0.009      -0.255      -0.036\n",
       "DailyRate                            -0.0353      0.030     -1.193      0.233      -0.093       0.023\n",
       "DistanceFromHome                      0.1028      0.029      3.509      0.000       0.045       0.160\n",
       "Education                             0.0060      0.034      0.177      0.860      -0.061       0.073\n",
       "EnvironmentSatisfaction              -0.1202      0.023     -5.137      0.000      -0.166      -0.074\n",
       "HourlyRate                           -0.0147      0.029     -0.501      0.617      -0.072       0.043\n",
       "JobInvolvement                       -0.1726      0.036     -4.805      0.000      -0.243      -0.102\n",
       "JobLevel                             -0.0048      0.110     -0.043      0.966      -0.221       0.211\n",
       "JobSatisfaction                      -0.1107      0.023     -4.782      0.000      -0.156      -0.065\n",
       "NumCompaniesWorked                    0.1544      0.034      4.510      0.000       0.087       0.222\n",
       "PercentSalaryHike                    -0.0320      0.051     -0.622      0.534      -0.133       0.069\n",
       "PerformanceRating                     0.0202      0.037      0.545      0.586      -0.053       0.093\n",
       "RelationshipSatisfaction             -0.0683      0.024     -2.881      0.004      -0.115      -0.022\n",
       "StockOptionLevel                     -0.0502      0.041     -1.225      0.221      -0.130       0.030\n",
       "TotalWorkingYears                    -0.1409      0.096     -1.462      0.144      -0.330       0.048\n",
       "TrainingTimesLastYear                -0.0799      0.040     -2.003      0.045      -0.158      -0.002\n",
       "WorkLifeBalance                      -0.0919      0.036     -2.541      0.011      -0.163      -0.021\n",
       "YearsAtCompany                        0.2214      0.120      1.848      0.065      -0.014       0.457\n",
       "YearsInCurrentRole                   -0.1664      0.070     -2.388      0.017      -0.303      -0.030\n",
       "YearsSinceLastPromotion               0.1627      0.052      3.157      0.002       0.062       0.264\n",
       "YearsWithCurrManager                 -0.1631      0.067     -2.420      0.016      -0.295      -0.031\n",
       "MonthlyRate                           0.0105      0.030      0.354      0.723      -0.048       0.069\n",
       "MonthlyIncome                        -0.0078      0.132     -0.059      0.953      -0.267       0.251\n",
       "BusinessTravel_Non-Travel             0.0644      0.026      2.436      0.015       0.013       0.116\n",
       "BusinessTravel_Travel_Frequently      0.2173      0.024      9.196      0.000       0.171       0.264\n",
       "BusinessTravel_Travel_Rarely          0.1292      0.020      6.390      0.000       0.090       0.169\n",
       "Department_Human Resources            0.0577      0.082      0.700      0.484      -0.104       0.219\n",
       "Department_Research & Development     0.1897      0.047      4.024      0.000       0.097       0.282\n",
       "Department_Sales                      0.1635      0.055      2.976      0.003       0.056       0.271\n",
       "EducationField_Human Resources        0.1535      0.070      2.196      0.028       0.016       0.291\n",
       "EducationField_Life Sciences          0.0314      0.022      1.453      0.146      -0.011       0.074\n",
       "EducationField_Marketing              0.0714      0.032      2.220      0.027       0.008       0.134\n",
       "EducationField_Medical                0.0163      0.023      0.722      0.471      -0.028       0.061\n",
       "EducationField_Other                  0.0106      0.035      0.300      0.764      -0.059       0.080\n",
       "EducationField_Technical Degree       0.1277      0.030      4.230      0.000       0.068       0.187\n",
       "JobRole_Healthcare Representative    -0.1397      0.058     -2.408      0.016      -0.253      -0.026\n",
       "JobRole_Human Resources               0.0789      0.117      0.676      0.499      -0.150       0.308\n",
       "JobRole_Laboratory Tech               0.7383      0.305      2.418      0.016       0.139       1.337\n",
       "JobRole_Laboratory Technician        -0.0067      0.058     -0.115      0.908      -0.120       0.107\n",
       "JobRole_Manager                      -0.0793      0.069     -1.141      0.254      -0.216       0.057\n",
       "JobRole_Manufacturing Dir            -0.0422      0.306     -0.138      0.891      -0.643       0.559\n",
       "JobRole_Manufacturing Director       -0.1253      0.058     -2.175      0.030      -0.238      -0.012\n",
       "JobRole_Research Dir                 -0.3121      0.308     -1.014      0.311      -0.916       0.291\n",
       "JobRole_Research Director            -0.1321      0.070     -1.875      0.061      -0.270       0.006\n",
       "JobRole_Research Scientist           -0.1043      0.058     -1.806      0.071      -0.218       0.009\n",
       "JobRole_Research scntist              0.5670      0.306      1.852      0.064      -0.034       1.168\n",
       "JobRole_Sales Executive              -0.0359      0.076     -0.474      0.636      -0.185       0.113\n",
       "JobRole_Sales Representative          0.1162      0.084      1.390      0.165      -0.048       0.280\n",
       "JobRole_mgr                          -0.1120      0.225     -0.499      0.618      -0.552       0.328\n",
       "MaritalStatus_Divorced                0.0966      0.025      3.907      0.000       0.048       0.145\n",
       "MaritalStatus_Married                 0.1076      0.021      5.222      0.000       0.067       0.148\n",
       "MaritalStatus_Single                  0.2067      0.023      8.932      0.000       0.161       0.252\n",
       "OverTime_No                           0.1005      0.027      3.711      0.000       0.047       0.154\n",
       "OverTime_Yes                          0.3104      0.027     11.309      0.000       0.257       0.364\n",
       "IsMale                                0.0328      0.017      1.890      0.059      -0.001       0.067\n",
       "==============================================================================\n",
       "Omnibus:                      284.912   Durbin-Watson:                   1.911\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              473.229\n",
       "Skew:                           1.278   Prob(JB):                    1.74e-103\n",
       "Kurtosis:                       4.092   Cond. No.                     1.00e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.07e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_model = sm.OLS(df1['Attrition_Yes'],df1.drop(['Attrition_Yes'],axis=1))\n",
    "sm_model1= sm_model.fit()\n",
    "sm_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(['Attrition_Yes'],axis=1)\n",
    "y = df1['Attrition_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_Research scntist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>JobRole_mgr</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>OverTime_No</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>IsMale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.909807</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.923407</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.350036</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.646385</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1106</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.799571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1185</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.382248</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1196</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.626342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1474</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.568361</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1653</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.479599</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeNumber       Age  DailyRate  DistanceFromHome  Education  \\\n",
       "0                  1  0.547619   0.715820          0.000000       0.25   \n",
       "1                  4  0.452381   0.909807          0.035714       0.25   \n",
       "2                  5  0.357143   0.923407          0.071429       0.75   \n",
       "3                  7  0.214286   0.350036          0.035714       0.00   \n",
       "4                  8  0.333333   0.646385          0.035714       0.25   \n",
       "...              ...       ...        ...               ...        ...   \n",
       "1465            1106  0.166667   0.799571          0.107143       0.00   \n",
       "1466            1185  0.404762   0.382248          0.107143       0.75   \n",
       "1467            1196  0.452381   0.626342          0.000000       0.50   \n",
       "1468            1474  0.523810   0.568361          0.035714       0.50   \n",
       "1469            1653  0.166667   0.479599          0.035714       0.00   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                    0.333333    0.914286        0.666667      0.25   \n",
       "1                    1.000000    0.885714        0.333333      0.00   \n",
       "2                    1.000000    0.371429        0.666667      0.00   \n",
       "3                    0.000000    0.142857        0.666667      0.00   \n",
       "4                    1.000000    0.700000        0.666667      0.00   \n",
       "...                       ...         ...             ...       ...   \n",
       "1465                 1.000000    0.028571        0.666667      0.00   \n",
       "1466                 1.000000    0.242857        0.333333      0.00   \n",
       "1467                 1.000000    0.371429        0.333333      0.25   \n",
       "1468                 0.666667    0.542857        0.666667      0.00   \n",
       "1469                 1.000000    0.671429        1.000000      0.25   \n",
       "\n",
       "      JobSatisfaction  ...  JobRole_Research scntist  JobRole_Sales Executive  \\\n",
       "0            1.000000  ...                       0.0                      1.0   \n",
       "1            0.666667  ...                       0.0                      0.0   \n",
       "2            0.666667  ...                       0.0                      0.0   \n",
       "3            0.333333  ...                       0.0                      0.0   \n",
       "4            1.000000  ...                       0.0                      0.0   \n",
       "...               ...  ...                       ...                      ...   \n",
       "1465         1.000000  ...                       0.0                      0.0   \n",
       "1466         1.000000  ...                       0.0                      0.0   \n",
       "1467         1.000000  ...                       0.0                      0.0   \n",
       "1468         0.666667  ...                       0.0                      0.0   \n",
       "1469         0.666667  ...                       0.0                      0.0   \n",
       "\n",
       "      JobRole_Sales Representative  JobRole_mgr  MaritalStatus_Divorced  \\\n",
       "0                              0.0          0.0                     0.0   \n",
       "1                              0.0          0.0                     0.0   \n",
       "2                              0.0          0.0                     0.0   \n",
       "3                              0.0          0.0                     0.0   \n",
       "4                              0.0          0.0                     0.0   \n",
       "...                            ...          ...                     ...   \n",
       "1465                           0.0          0.0                     0.0   \n",
       "1466                           0.0          0.0                     0.0   \n",
       "1467                           0.0          0.0                     0.0   \n",
       "1468                           0.0          0.0                     1.0   \n",
       "1469                           0.0          0.0                     1.0   \n",
       "\n",
       "      MaritalStatus_Married  MaritalStatus_Single  OverTime_No  OverTime_Yes  \\\n",
       "0                       0.0                   1.0          0.0           1.0   \n",
       "1                       0.0                   1.0          0.0           1.0   \n",
       "2                       1.0                   0.0          0.0           1.0   \n",
       "3                       1.0                   0.0          1.0           0.0   \n",
       "4                       0.0                   1.0          1.0           0.0   \n",
       "...                     ...                   ...          ...           ...   \n",
       "1465                    1.0                   0.0          0.0           1.0   \n",
       "1466                    1.0                   0.0          1.0           0.0   \n",
       "1467                    1.0                   0.0          1.0           0.0   \n",
       "1468                    0.0                   0.0          1.0           0.0   \n",
       "1469                    0.0                   0.0          1.0           0.0   \n",
       "\n",
       "      IsMale  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "...      ...  \n",
       "1465     1.0  \n",
       "1466     1.0  \n",
       "1467     0.0  \n",
       "1468     0.0  \n",
       "1469     0.0  \n",
       "\n",
       "[1470 rows x 56 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_Research scntist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>JobRole_mgr</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>OverTime_No</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>IsMale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>407</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.332140</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>408</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.858984</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>410</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508232</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>412</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.983536</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1106</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.799571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1185</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.382248</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1196</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.626342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1474</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.568361</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1653</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.479599</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1177 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeNumber       Age  DailyRate  DistanceFromHome  Education  \\\n",
       "293              407  0.428571   0.332140          0.607143       0.75   \n",
       "294              408  0.785714   0.858984          0.035714       0.50   \n",
       "295              410  0.547619   0.166070          0.035714       0.75   \n",
       "296              411  0.000000   0.508232          0.321429       0.50   \n",
       "297              412  0.238095   0.983536          0.535714       0.25   \n",
       "...              ...       ...        ...               ...        ...   \n",
       "1465            1106  0.166667   0.799571          0.107143       0.00   \n",
       "1466            1185  0.404762   0.382248          0.107143       0.75   \n",
       "1467            1196  0.452381   0.626342          0.000000       0.50   \n",
       "1468            1474  0.523810   0.568361          0.035714       0.50   \n",
       "1469            1653  0.166667   0.479599          0.035714       0.00   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "293                  0.666667    0.728571        1.000000      0.00   \n",
       "294                  1.000000    0.771429        0.000000      0.25   \n",
       "295                  1.000000    0.828571        0.666667      0.75   \n",
       "296                  1.000000    0.557143        0.333333      0.00   \n",
       "297                  0.333333    0.542857        1.000000      0.25   \n",
       "...                       ...         ...             ...       ...   \n",
       "1465                 1.000000    0.028571        0.666667      0.00   \n",
       "1466                 1.000000    0.242857        0.333333      0.00   \n",
       "1467                 1.000000    0.371429        0.333333      0.25   \n",
       "1468                 0.666667    0.542857        0.666667      0.00   \n",
       "1469                 1.000000    0.671429        1.000000      0.25   \n",
       "\n",
       "      JobSatisfaction  ...  JobRole_Research scntist  JobRole_Sales Executive  \\\n",
       "293          1.000000  ...                       0.0                      0.0   \n",
       "294          0.333333  ...                       0.0                      0.0   \n",
       "295          0.333333  ...                       0.0                      0.0   \n",
       "296          0.666667  ...                       0.0                      0.0   \n",
       "297          0.000000  ...                       0.0                      0.0   \n",
       "...               ...  ...                       ...                      ...   \n",
       "1465         1.000000  ...                       0.0                      0.0   \n",
       "1466         1.000000  ...                       0.0                      0.0   \n",
       "1467         1.000000  ...                       0.0                      0.0   \n",
       "1468         0.666667  ...                       0.0                      0.0   \n",
       "1469         0.666667  ...                       0.0                      0.0   \n",
       "\n",
       "      JobRole_Sales Representative  JobRole_mgr  MaritalStatus_Divorced  \\\n",
       "293                            0.0          0.0                     0.0   \n",
       "294                            0.0          0.0                     1.0   \n",
       "295                            0.0          0.0                     0.0   \n",
       "296                            1.0          0.0                     0.0   \n",
       "297                            0.0          0.0                     0.0   \n",
       "...                            ...          ...                     ...   \n",
       "1465                           0.0          0.0                     0.0   \n",
       "1466                           0.0          0.0                     0.0   \n",
       "1467                           0.0          0.0                     0.0   \n",
       "1468                           0.0          0.0                     1.0   \n",
       "1469                           0.0          0.0                     1.0   \n",
       "\n",
       "      MaritalStatus_Married  MaritalStatus_Single  OverTime_No  OverTime_Yes  \\\n",
       "293                     1.0                   0.0          1.0           0.0   \n",
       "294                     0.0                   0.0          1.0           0.0   \n",
       "295                     0.0                   1.0          1.0           0.0   \n",
       "296                     0.0                   1.0          1.0           0.0   \n",
       "297                     0.0                   1.0          1.0           0.0   \n",
       "...                     ...                   ...          ...           ...   \n",
       "1465                    1.0                   0.0          0.0           1.0   \n",
       "1466                    1.0                   0.0          1.0           0.0   \n",
       "1467                    1.0                   0.0          1.0           0.0   \n",
       "1468                    0.0                   0.0          1.0           0.0   \n",
       "1469                    0.0                   0.0          1.0           0.0   \n",
       "\n",
       "      IsMale  \n",
       "293      1.0  \n",
       "294      1.0  \n",
       "295      1.0  \n",
       "296      0.0  \n",
       "297      1.0  \n",
       "...      ...  \n",
       "1465     1.0  \n",
       "1466     1.0  \n",
       "1467     0.0  \n",
       "1468     0.0  \n",
       "1469     0.0  \n",
       "\n",
       "[1177 rows x 56 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[293:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold (Testing out StratifiedKFold )\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_xgb =[]\n",
    "\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index],y.loc[train_index], y.loc[test_index]\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))\n",
    "    #scores_xgb.append(get_score())\n",
    "\n",
    "# KFold\n",
    "#from sklearn.model_selection import KFold\n",
    "#kf = KFold(n_splits=5)\n",
    "#for train_index, test_index in kf.split(X,y):\n",
    "#    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index],y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9081632653061225,\n",
       "  0.8809523809523809,\n",
       "  0.8707482993197279,\n",
       "  0.8775510204081632,\n",
       "  0.8843537414965986],\n",
       " [0.8367346938775511,\n",
       "  0.8367346938775511,\n",
       "  0.7482993197278912,\n",
       "  0.826530612244898,\n",
       "  0.8401360544217688],\n",
       " [0.8469387755102041,\n",
       "  0.8605442176870748,\n",
       "  0.8639455782312925,\n",
       "  0.8571428571428571,\n",
       "  0.8571428571428571])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_logistic,scores_svm,scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90677966, 0.86382979, 0.85106383, 0.85957447, 0.87234043])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(), X_train, y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83898305, 0.83829787, 0.83829787, 0.83829787, 0.83829787])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(),  X_train, y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8537415 , 0.85714286, 0.86734694, 0.86394558, 0.8537415 ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(), X, y,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this cross val score, Logistic Regression has the better score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'n_estimators': [1,5,10,100],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'solver' : ['lbfgs','liblinear'],\n",
    "            'C': [0.01,0.1,1,5,10],\n",
    "            'penalty' : ['l2']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost_Classifier' : {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate' : [0.001,0.1,1],\n",
    "            'n_estimators' : [100,500,1000],\n",
    "            'max_depth' : [5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.877533</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.861399</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.870718</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_Classifier</td>\n",
       "      <td>0.857984</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.877533   \n",
       "1        random_forest    0.861399   \n",
       "2  logistic_regression    0.870718   \n",
       "3   XGBoost_Classifier    0.857984   \n",
       "\n",
       "                                         best_params  \n",
       "0                       {'C': 1, 'kernel': 'linear'}  \n",
       "1  {'max_features': 'auto', 'min_samples_leaf': 2...  \n",
       "2       {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}  \n",
       "3  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GridSearch CV\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, model_p in model_params.items():\n",
    "    clf =  GridSearchCV(model_p['model'], model_p['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:59:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:00:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.877533</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.861399</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.870718</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_Classifier</td>\n",
       "      <td>0.857984</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.877533   \n",
       "1        random_forest    0.861399   \n",
       "2  logistic_regression    0.870718   \n",
       "3   XGBoost_Classifier    0.857984   \n",
       "\n",
       "                                         best_params  \n",
       "0                       {'C': 1, 'kernel': 'linear'}  \n",
       "1  {'max_features': 'auto', 'min_samples_leaf': 2...  \n",
       "2       {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}  \n",
       "3  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RandomSearch CV\n",
    "scores_rs=[]\n",
    "\n",
    "for model_name, model_p in model_params.items():\n",
    "    clf1 =  RandomizedSearchCV(model_p['model'], model_p['params'], cv=5, n_iter = 50,random_state=0)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    scores_rs.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf1.best_score_,\n",
    "        'best_params': clf1.best_params_\n",
    "    })\n",
    "    \n",
    "df2 = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression shows better score than other models__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1233\n",
       "1     237\n",
       "Name: Attrition_Yes, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Attrition_Yes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Oversampling for Handling Imbalanced \n",
    "smk = SMOTETomek(random_state=42)\n",
    "X_train,y_train=smk.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1836, 56), (1836,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred1 = lr.predict_proba(X_test)[:,1]  # all rows, column 1\n",
    "\n",
    "ypred_threshold=np.zeros([len(y_test),1])\n",
    "ypred_threshold[y_pred1>0.4 ]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_threshold[:5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16172382 0.83827618]\n",
      " [0.01027319 0.98972681]\n",
      " [0.34740106 0.65259894]\n",
      " [0.90976639 0.09023361]\n",
      " [0.46248508 0.53751492]]\n"
     ]
    }
   ],
   "source": [
    "print (try1[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,average_precision_score,roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Not Attrition', 'Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Attrition       0.94      0.80      0.86       247\n",
      "    Attrition       0.41      0.74      0.53        47\n",
      "\n",
      "     accuracy                           0.79       294\n",
      "    macro avg       0.68      0.77      0.70       294\n",
      " weighted avg       0.86      0.79      0.81       294\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Attrition       0.95      0.72      0.82       247\n",
      "    Attrition       0.36      0.81      0.49        47\n",
      "\n",
      "     accuracy                           0.73       294\n",
      "    macro avg       0.65      0.76      0.66       294\n",
      " weighted avg       0.86      0.73      0.77       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_pred,target_names =target_names ))\n",
    "print (classification_report(y_test,ypred_threshold,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[197,  50],\n",
       "        [ 12,  35]]),\n",
       " array([[178,  69],\n",
       "        [  9,  38]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = (confusion_matrix(y_test,y_pred))\n",
    "cm1 = (confusion_matrix(y_test,ypred_threshold))\n",
    "cm,cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted');ax.set_ylabel('Actuals'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Not Attrition', 'Attrition']); ax.yaxis.set_ticklabels(['Not Attrition', 'Attrition']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm1, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted');ax.set_ylabel('Actuals'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Not Attrition', 'Attrition']); ax.yaxis.set_ticklabels(['Not Attrition', 'Attrition']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31774686410654934"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, ypred_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 38\n",
      "False Positives: 69\n",
      "True Negatives: 178\n",
      "False Negatives: 9\n"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, ypred_threshold).ravel()\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Negatives: {fn}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__True Postive Rate(sensitivity)__\n",
    "tpr = tp/(tp+fn)\n",
    "\n",
    "__False Positive Rate(1- specificity)__\n",
    "fpr = fp/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score :  0.7645792057886123\n"
     ]
    }
   ],
   "source": [
    "print ('ROC AUC Score : ',roc_auc_score(y_test,ypred_threshold) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1_fpr,plt1_tpr,_ = roc_curve(y_test,ypred_threshold)\n",
    "plt_fpr,plt_tpr,_ = roc_curve(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU9Znv8c/TKzTd7NANzQ7djftCC2hiFBVBTa5ZnITEmSROvF4ncWKWa9R5vW6Sm5n7iiYaNRMNwzBiMjEy2WNmjKhxjxKBcVcamr3Zm7UX6PW5f1TRXTTdTQN16nTV+b5fr35Zp86vq54DeJ6q33PO8zN3R0REoisr7ABERCRcSgQiIhGnRCAiEnFKBCIiEadEICIScUoEIiIRp0QgIhJxSgSSUcxso5kdMrN6M9thZo+YWWGXMReZ2bNmVmdmB8zsD2Z2epcxg83sfjPbHH+t6vj2yB7e18zsy2b2jpk1mFmNmf3SzM4K8nhFkkGJQDLRR9y9EDgXOA+488gOM7sQeAr4PTAWmAy8CfzZzKbEx+QBfwLOAOYDg4GLgD3AzB7e8wHgVuDLwHCgHPgdcM2JBm9mOSf6OyKnwnRnsWQSM9sI3Ojuz8S3vwec4e7XxLdfAt529y92+b0/Arvd/bNmdiPw/4Cp7l7fh/csA1YDF7r7az2MeR74mbsvjm9/Ph7nB+PbDtwCfAXIAZYB9e7+vxNe4/fAC+7+AzMbC/wz8CGgHrjP3X/Yhz8ikWPoG4FkLDMbB1wFVMe3C4h9sv9lN8N/AcyNP74CeLIvSSDucqCmpyRwAj4KzAJOB34OfMrMDMDMhgFXAkvNLAv4A7FvMqXx9/+Kmc07xfeXiFIikEz0OzOrA7YAu4BvxZ8fTuzf/PZufmc7cGT+f0QPY3pyouN78l133+vuh4CXAAcuju+7DnjV3bcBFwCj3P077t7s7uuBfwUWJCEGiSAlAslEH3X3IuBSYDqdJ/h9QDswppvfGQPUxh/v6WFMT050fE+2HHngsTnbpcCn4099Bng0/ngiMNbM9h/5Af4BKE5CDBJBSgSSsdz9BeAR4J74dgPwKvBX3Qz/JLECMcAzwDwzG9THt/oTMM7MKnsZ0wAUJGyXdBdyl+3HgOvMbCKxKaNfx5/fAmxw96EJP0XufnUf4xU5ihKBZLr7gblmdm58+w7gc/FLPYvMbJiZ/RNwIfB/42P+ndjJ9tdmNt3MssxshJn9g5kdc7J197XAQ8BjZnapmeWZ2QAzW2Bmd8SHvQF83MwKzGwa8IXjBe7urwO7gcXAMnffH9/1GnDQzG43s4Fmlm1mZ5rZBSfzBySiRCAZzd13Az8F/k98+2VgHvBxYvP6m4hdYvrB+Akdd28iVjBeDTwNHCR28h0J/KWHt/oy8CPgQWA/sA74GLGiLsB9QDOwE/gJndM8x/NYPJafJxxTG/ARYpfHbiA2pbUYGNLH1xQ5ii4fFRGJOH0jEBGJOCUCEZGIUyIQEYk4JQIRkYhLu+ZWI0eO9EmTJoUdhohIWlm1alWtu4/qbl/aJYJJkyaxcuXKsMMQEUkrZrapp32aGhIRiTglAhGRiFMiEBGJOCUCEZGIUyIQEYm4wBKBmT1sZrvM7J0e9puZ/TC+KPhbZnZ+ULGIiEjPgvxG8Aixhb97chVQFv+5CfhxgLGIiKS1VZv28eBz1azatC/prx3YfQTu/qKZTeplyLXAT+MrMS03s6FmNsbdk7Hkn4hI8FYugbd/FdjLO05Tazt7G5pp3dtIQftErn/28zx642xmTByWtPcJ84ayUhKW5gNq4s8dkwjM7CZi3xqYMGFCSoITEenRc9+FF+469vkh42HoxJN6yea2dg41t9HY3MqhljYam2M/Y9nFOKtlbBbMynqfG3gSlgCX3AFz7jy144gLMxFYN891uziCuy8CFgFUVlZqAQURCdecO2M/S66Jbd/wX33+1YOHW1i7s46qHfWs2VlH1Y461uysY09Dc8eY4YPyqCguoqKkiPLiIgC+84d3aWlrJzcnK6O+EdQA4xO2xwHbQopFRCSpDre0Ub0rfrLfWceaHbGT/rYDhzvGDMrLprykiLmnF1MeP/FXlBQxsjD/mNerKCli+fo9zJ4yIqlJAMJNBI8Dt5jZUmILcx9QfUBEQnMy8/073sZLzmTdrqM/3VftqGPjngba4/MXedlZTB1dyMzJwykvKer4tF86dCBm3U2OHGvGxGFJTwBHBJYIzOwx4FJgpJnVAN8CcgHcfSHwBHA1UA00AjcEFYuISI/6ON/vOM2t7TQ2t5F9cAuDm2KfW23Tn5n2UCnTgLWtH6dq6OcoLy7iw+eMjZ/wC5k0YhA52f33tq20W7O4srLS1X1URJIuYb6/tr4pNpWzsy7hk3499U2tHcPHDhnQ8en+yLTOtNGFDMjNDukAemdmq9y9srt9adeGWkQkWeoOt7BmZ2xa58I9DTQ2t/HZf3qa2vrOwu2wglwqSor4xPmlHSf+suIihgzMDTHy5FIiEJGMd7iljXW7j8zjd87nb91/qGPML/KbKMjL5vLpxZ2f9EsKGVWY3+d5/HSlRCAiyRXwTVa9cZzDLe2xa/Gb22iMX49/uKUNgDHAWODq3GwG5mVTUJxDQV7scX5tDVZyNndfd3YosYdJiUBEkiOAm6x6kli47bz5KnYjVmLZc0BO7CQ/YlBexwl/QG42WYm3Me3fBLvj97Zuehm+PST2OIk3bPV3SgQikhyncJNVb/bUN3Vehx+fz1+zo466hMLtmCEDKB/beQNWRXGscDswr38WbvsbJQIR6Rfqm1o7TvKdV+vUU1vf1DFmaEEuFcVFfOz80o4rdcpHFzGkIHMKt2FQIhBJphDnx/uNHW9DyVk97m5qbWPdroaj77jdWUfNvs7C7cDc2B23l00f1XnHbXERo4oyv3AbBiUCkWRI4fx4v7V/Exw4dq69+rQv8V8jbug48W+obaAtfsttTpYxdVQh508YxqdnTuiY1hk3bCBZWTrhp4puKBNJpiTPj6cDd2f7gcNHfbpfs7OOtTvraWptB8AMJgwvOKqRWkVJEZNGDCIvp//ecZtJdEOZiCTF3obmzn46CSf+usOdhdviwfmUFxfx2QsnHnXHbUGeTjf9lf5mJLOles7+OPPj6aLhSOE28QasnXXsruss3A4ZGCvcfvTc0oRWC4UMLcgLMXI5GUoEkplSPWffw/x4f78Wvbm1PeGO285P+lv2dhZuB+RmUV5cxCXlo5ieMK0zWoXbjKEagWS2CM7Zd6et3dm8t/GYaZ0NtQ20JhRup4waRHlx0VEn/PHDClS4zQCqEYhEhLuz82ATq3ccPGpaZ+2uOg63tHeMmzC8gPLiIq48o5iKksFUFBcxeaQKt1GlRCCZo7t6QIbM2XdnX0NzlzbJsf8eTCjcji7Kp6KkiOtnTey4Fn/a6EIG5et/femkfw2S/nqqBxyRRnP23Wlsbo21Su7SH39XQuF28IAcKkqK+Mg5YzumdcqLixg2SIVbOT4lAkl/AfW4SbXm1nY21DYcM62zeW9jx5gBuVmUjS7i4rJRVJQUdkzrFA9W4VZOnhKBSIq1tztb9jWyesfRN2Ct391ZuM3OMqaMHMRZ44Zw3YxxHdM644cXkK3CrSSZEoGEI4jr+/tZPcDd2VXXdMwJf+3Oeg7F++MDjB8+kIriIq44rTh2wi+JFW7zc9Q5U1JDiUBSK4jr+/vBNfz7G7vecVtP1c46Dhxq6RgzqiifiuIiPj1zQse0TpkKt9IP6D4CCUeazuc3Nreydmf9MX11dh7sLNwWDciJL3NYdFRvneEq3EqIdB+ByAlqaTtSuD36hL95b2PHClj5OVmUFRfygWkjO07800uKKBk8QIVbSStKBBJp7e1Ozb5DnVfqxC/TXF9bT0tbZ+F28shBnDl2CB8/bxwVJYWUFxcxccQgFW4lIygRSGodKRKnuLDr7uyuiy15WLWj8wasNV0Kt+OGxQq3l502Ot5ErYipo1W4lcymRCCp0V2ROKDC7oHGFtbsqjtmWmd/Y2fhdmRhPhUlhSyYOb5jWqdsdCFFA7TkoUSPisWSWkksEh9qbqN6V/0x0zo7Dh7uGFOUn0N5x4LmhR0F3BGF+af8/iLpRMViSWstbe1srG04ZlpnU0LhNi8ni7LRhVw0dURnb/ySIsYOUeFW5HiUCCQ4J9gErr3d2br/UGxKJ6GR2rrdnYXbLIPJIwdx+tjBfPS80o4T/sThBeRkq3OmyMlQIpDkO4EmcP89+X+xdND1VO2sZ+3OOhqbOwu3pUMHUlFSxKUVozuu1Jk6qpABuSrciiSTagQSnCXX0NrezhuXP3rMp/x9CYXbEYPyjlrQvDy+5KEKtyLJoxqBBGLVpn0sX7+H2VNGcMbYwfHCbecJ/9Yt+2hua2fBwlcBKMzPoby4kPlnlsSLt7FpnZEq3IqEKtBEYGbzgQeAbGCxu9/VZf8Q4GfAhHgs97j7kiBjkiRYuYS6lY/Ruv0gMxxanoM34rvGAeOBD+dlU2ab2DusgoevqqS8uIjSoQNVuBXphwJLBGaWDTwIzAVqgBVm9ri7v5cw7EvAe+7+ETMbBVSZ2aPu3hxUXHIKEub+i4BZBhjU+EgO5o+leHA+BXk5DGioweJN4EoPrKJ0aXns99NwURiRKAjyG8FMoNrd1wOY2VLgWiAxEThQZLGPiYXAXqC16wtJP5GwAMzu+iYu2PpVDMjPzeLR62czYuKwsCMUkZMQZCIoBbYkbNcAs7qM+RHwOLCN2IfMT7l7e5cxmNlNwE0AEyZMCCRYOTF7G5opyM3mbz84mTnTRzNDSUAkbQWZCLqbDO56idI8YtPLlwFTgafN7CV3P3jUL7kvAhZB7KqhAGKNppNcHKZ1+5vsOzyOL86Zyi2XlQUQmIikUpCJoIZY3fCIccQ++Se6AbjLY9ewVpvZBmA68FqAccnJLg4TXwAmB5id9T6zX6yEF9Hcv0iaCzIRrADKzGwysBVYAHymy5jNwOXAS2ZWDFQA6wOMSeCUFnt/rmoXNyxZwXeuPYPPXjgpmPhEJKUCSwTu3mpmtwDLiF0++rC7v2tmN8f3LwT+EXjEzN4mNpV0u7vXBhWTnJr2dud7T1YxYXgBCy5QrUYkUwR6H4G7PwE80eW5hQmPtwFXBhmDJM8f3trG+9sP8sCCc8nLUV8fkUyh/5ulT5pb27n3qTVMLyniI2ePDTscEUkiJQLpk/9YsZnNexu5ff50srQ8o0hGUSKQ42psbuWBP1Uzc9JwLq0YFXY4IpJkSgRyXEv+vJHa+iZuv6pCvYJEMpC6j6azk7whrEMfFpDf19DMwufXccVpxcyYOPzk30tE+i0lgnR0sjeEHRG/MQw47gLyC19YR31zK7fNqzjFoEWkv1IiSEencEPYidh+4BCPvLKRj51XSkVJUSDvISLhU41AevTAM2tpd+erV5SHHYqIBEiJQLpVvaueX6zcwvWzJjJ+eEHY4YhIgJQIpFs/eLqKgbnZ3HLZtLBDEZGAKRHIMd7csp8n3t7BjRdP0XrCIhGgRCDH+P6yKoYPyuPGiyeHHYqIpIASgRzl5bW1vFxdy5fmTKNoQG7Y4YhICigRSAd35+4nV1M6dCDXz1KbaZGoUCKQDn98Zwdvbz3AV+eWMyA3O+xwRCRFlAgEgNa2du5ZVkXZ6EI+dl5p2OGISAopEaSrlUti7SGS5Feralhf28Bt8yrIVptpkUhRi4l007XP0HF6BfXF4ZY27n9mLedNGMrc04uTFKiIpAslgnQTQJ+hn7yykR0HD3P/gnPVZlokgjQ1FHEHDrXw0PPruLRiFLOnjAg7HBEJgRJBxC16cR0HDrWozbRIhGlqqD/rbeGZPiwqczy7Dh7m4Zc38j/OGcsZY4ec0muJSPpSIuiPelt4Bvq8qMzx/PDZtbS0tfO1uWozLRJlSgT9UQoWntlY28DS17awYOZ4Jo0clPTXF5H0oRpBRP3g6TXkZmfx5cvKwg5FREKmbwT9RXf1gCTUAbrz7rYDPP7mNr40ZyqjBw9I+uuLSHpRIghbT/WAI5Jww1hX319WxZCBudz0oamn/Foikv6UCMKWooXoj1i+fg/PV+3mzqumM2Sg2kyLiGoEkXKkzXTx4Hw+d9GksMMRkX5C3whSrad7AwKqByR6+r2dvL55P9/9+FlqMy0iHQJNBGY2H3gAyAYWu/sxk+FmdilwP5AL1Lr7JUHGFJqeagH5g6HpYOxxAPWAI9rane8vq2LKyEH81YxxSXtdEUl/gSUCM8sGHgTmAjXACjN73N3fSxgzFHgImO/um81sdFDxhC7FtYCufvv6Vtbuqueh688nJ1szgiLSKcgzwkyg2t3Xu3szsBS4tsuYzwC/cffNAO6+K8B4IutwSxv3Pb2Gs0qHcNWZJWGHIyL9TJBTQ6XAloTtGmBWlzHlQK6ZPQ8UAQ+4+0+7vpCZ3QTcBDBhQj9eS7e33kBHpKAW0NWjf9nM1v2HuPsTZ6vNtIgcI8hE0N0Zx7t5/xnA5cBA4FUzW+7ua476JfdFwCKAysrKrq8Rvt56Aw2dGHu8f1PSegSdiLrDLTz4XDUfmDaCD5aNDOx9RCR9BZkIaoDxCdvjgG3djKl19wagwcxeBM4B1pBOQp7/783ilzawt6GZb8ybHnYoItJPBVkjWAGUmdlkM8sDFgCPdxnze+BiM8sxswJiU0fvBxhTpNTWN7H4pfVcfVYJ54wfGnY4ItJPBZYI3L0VuAVYRuzk/gt3f9fMbjazm+Nj3geeBN4CXiN2iek7QcUUqCQvJp8MP3q2msOt7Xz9Si06IyI9M/f+N+Xem8rKSl+5cmXYYXTqrVdQwPP/vdmyt5HL7n2eT5w/jrs+cXYoMYhI/2Fmq9y9srt9urP4VPXT+sB9z6why4xbr1CbaRHpne4sykBVO+r47etb+fxFkxgzZGDY4YhIP6dEkIG+v6yKwvwc/u5StZkWkeNTIsgwKzfu5Zn3d3LzJVMZWpAXdjgikgaUCDLIkTbTIwvzueEDk8IOR0TShBJBBnm+ajcrNu7j1sunUZCn6wBEpG9OOBGYWbaZXR9EMHLy2ttj3wYmjihgwcx+3I9JRPqdHhOBmQ02szvN7EdmdqXF/D2wHvhk6kKUvvjDW9tYvaOOr80tJ1dtpkXkBPQ2f/DvwD7gVeBG4DYgD7jW3d9IQWzSR82t7dz71BpOGzOYj5w9NuxwRCTN9JYIprj7WQBmthioBSa4e11KIpM+W7piM5v3NrLkhgvIylKbaRE5Mb3NIbQceeDubcAGJYH+p6GplR/+qZqZk4dzafmosMMRkTTU2zeCc8zsIJ3rCgxM2HZ3Hxx4dP1d4kI0ISw4A7DkzxuorW/iX/5mhhadEZGT0mMicPfsVAaSVnpqNJfCBWcA9jU08y8vrGfu6cXMmDgs0PcSkczVYyIwswHAzcA0Ym2iH463lpZ+0mjuxy+so765ldvmqc20iJy83moEPwEqgbeBq4F7UxKR9Mm2/Yd45JWNfPy8cZQXF4Udjoiksd5qBKcnXDX0b8QWjpF+UBcAeOCZteDw1blqMy0ip6a3RJB41VBr5AuR/aQuAFC9q55frtrC5y+azLhhBYG/n4hktt4Swbnxq4QgdqVQtK8a6id1AYB7n6piYG42X5qjNtMicup6SwRvuvt5KYtE+uTNLfv54zs7+MoVZYwozA87HBHJAL0Vi9NrMeMIONJmevigPG68eErY4YhIhujtG8FoM/taTzvd/QcBxCO9eLm6llfW7eGbHz6dwny1mRaR5OjtbJINFNJ5Z7GEqL3d+d6TVZQOHcj1s9VmWkSSp7dEsN3dv5OySKRXf3xnB29vPcC9f3UO+Tm66VtEkqe3GoG+CfQTLW3t3PNUFeXFhXz0vNKwwxGRDNNbIrg8ZVFIr365soYNtQ3cNm862WozLSJJ1mMicPe9qQxEuneouY0H/rSGGROHccVpo8MOR0QykNY07Od+8upGdh5s4vb509VmWkQCoUTQjx1obOGh56qZUzGKmZOHhx2OiGQoXYzek8TmcolS2GjuX15cx8HDrdw2b3pK3k9EokmJoKuemsvlD4ameOulFDSa23nwMA//eQPXnjuW08dGq62TiKSWEkFX/aS53A//tJbWNudrc8tDeX8RiY5AawRmNt/Mqsys2szu6GXcBWbWZmbXBRlPuthQ28DSFVv4zKwJTBwxKOxwRCTDBfaNwMyygQeBuUANsMLMHnf397oZdzewLKhYjqu7ekCIi8784Ok15GVncctl00J5fxGJliCnhmYC1e6+HsDMlgLXAu91Gff3wK+BCwKMpXs91QOOCGHRmXe2HuAPb27jljnTGF00IPD3ExEJMhGUAlsStmuAWYkDzKwU+BhwGb0kAjO7CbgJYMKEJDZc6yf1gETfW1bF0IJcbrpEbaZFJDWCrBF0d/dT1zUO7gdud/e23l7I3Re5e6W7V44aNSppAfY3r6yr5cU1u/nipVMZPCA37HBEJCKC/EZQA4xP2B4HbOsyphJYGr9jdiRwtZm1uvvvAoyrX3KPtZkeM2QAn71wUtjhiEiEBJkIVgBlZjYZ2AosAD6TOMDdJx95bGaPAP8ZxSQA8NR7O3ljy37u/sRZDMhVm2kRSZ3AEoG7t5rZLcSuBsoGHnb3d83s5vj+hUG9d7ppa3e+v6yKKaMG8Ynzx4UdjohETKA3lLn7E8ATXZ7rNgG4++eDjKU/+81/11C9q54fX38+Odlq/yQiqaWzTsgOt7Rx39NrOGfcEOafWRJ2OCISQUoEIfvZ8k1sO3BYbaZFJDRKBCGqO9zCg89Vc3HZSC6aNjLscEQkopQIQvSvL21gX2MLt82rCDsUEYkwJYKQ1NY3sfil9Vxz1hjOHjc07HBEJMKUCELyo2eraWpt5+tXqs20iIRLiSAEW/Y28uhfNvHJyvFMGVUYdjgiEnFKBCG47+k1ZJlx6+VlYYciIqJEkGqrdxzkt29s5fMfmETJELWZFpHwRTsRrFwSa0G94+2UveU9y6oozM/h7y6ZmrL3FBHpTTTXLO5uQZoULEKzYuNennl/F7fNq2BoQV7SX19E5GREMxGEsCCNu3P3H1czuiifv/3A5OP/gohIikR7aiiFnqvaxcpN+/jy5WUMzFObaRHpP5QIUqC9PbbozMQRBXzqgvHH/wURkRRSIkiBx9/cxuoddXz9ygpy1WZaRPoZnZUC1tzazr1PV3HG2MF8+KwxYYcjInIMJYKAPfbaZrbsPcQ35k8nK0ttpkWk/1EiCFBDUyv//OxaZk8ZzofK1GZaRPonJYIAPfzyBmrrm/mGFp0RkX5MiSAgexuaWfTieq48vZjzJwwLOxwRkR4pEQTkoeeqaWhu1aIzItLvRTcRrFwSaysRgK37D/HT5Zv4xPnjKCsuCuQ9RESSJXotJrr2GQqgx9ADz6wBh6/M1aIzItL/RS8RBNxnqHpXHb9aVcMNH5hM6dCBSX1tEZEgRHdqKCD3LFtDQV4OX7xUbaZFJD0oESTR65v38eS7O/ifF09hRGF+2OGIiPRJNBNBAIVid+fuJ1czYlAeN16sNtMikj6iVSMIsFD80tpalq/fy7c/cjqD8qP1xyoi6S1aZ6yACsXt7c73lq1m3LCBfHrWhKS8pohIqkRzaijJnnhnO+9sPcjX5paTn6NFZ0QkvQSaCMxsvplVmVm1md3Rzf7rzeyt+M8rZnZOkPEASa8PtLS1c+9Ta6goLuLac0uT9roiIqkS2NSQmWUDDwJzgRpghZk97u7vJQzbAFzi7vvM7CpgETArkIACqg/8YuUWNtQ28G+fqyRbbaZFJA0FWSOYCVS7+3oAM1sKXAt0JAJ3fyVh/HJgXGDRBFAfONTcxgPPrKVy4jAumz76lF9PRCQMQU4NlQJbErZr4s/15AvAH7vbYWY3mdlKM1u5e/fuJIZ4ah55ZSO76pq4/Sq1mRaR9BVkIujuzOjdDjSbQywR3N7dfndf5O6V7l45atSoJIZ48g40tvDj56u5bPpoLpg0POxwREROWpBTQzXA+ITtccC2roPM7GxgMXCVu+8JMJ6kWvjiOuqa1GZaRNJfkN8IVgBlZjbZzPKABcDjiQPMbALwG+Bv3H1NgLEk1c6Dh1ny5w189NxSThszOOxwREROSWDfCNy91cxuAZYB2cDD7v6umd0c378Q+CYwAngoPsfe6u6VQcWULA/8aS1t7c5Xr1CbaRFJf4HeWezuTwBPdHluYcLjG4Ebg4wh2TbUNvAfK7bw17MmMGFEQdjhiIicMt1ZfILufaqK/JwsbrmsLOxQRESSQongBLyz9QD/+dZ2vvDByYwqUptpEckMSgQn4O4nVzOsIJf/+aEpYYciIpI0SgR99Ep1LS+treVLc6YxeEBu2OGIiCSNEkEfuDt3L6tizJAB/PXsiWGHIyKSVEoEfbDs3Z28uWU/X72inAG5ajMtIplFieA4WtvaueepKqaOGsTHz1ebaRHJPEoEx/Gb/95K9a56bps3nZxs/XGJSObRma0Xh1vauO+ZNZwzfijzzigOOxwRkUAoEfTiZ8s3sf3AYW6fX6E20yKSsZQIenDwcAsPPlfNxWUjuWjqyLDDEREJjBJBDxa/uJ59jS3cPn962KGIiARKiaAbu+uaWPzyBj589hjOLB0SdjgiIoFSIujGj55dS1NrO1+/UovOiEjmUyLoYvOeRn7+2mY+dcF4Jo8cFHY4IiKBUyLo4r5n1pBlxq2Xq820iERDdBLByiWw5BrY8XaPQ97ffpDfvbGVGz4wmeLBA1IYnIhIeAJdoaxfeO678MJdRz+36WX4drwIfMkdMOdOAL6/rIqi/Bz+7pKpKQ5SRCQ8mZ8I5twZ+1lyTWz7hv/qdthrG/by7Opd3D5/OkMK1GZaRKIjOlNDvXB3vvfkakYX5fP5iyaFHY6ISEopEQDPrt7Fyk37uPWKMgbmqc20iERL5BNBW7vzvSermDSigE9Wjg87HBGRlIt8Ivj9G1up2lnH16+sIFdtpkUkgiJ95mtqbeMHT6/hzNLBXHPWmLDDEREJRaQTwWN/2UzNvkN8Y950srLUZlpEoimyiaC+qZV/fraaC6eM4OIytZkWkf4n/h0AAAbYSURBVOiKbCJ4+OUN7Glo5htadEZEIi6SiWBvQzOLXlzPvDOKOW/CsLDDEREJVSQTwYPPVdPY3Mpt89RmWkQkcolg6/5D/Purm7huxjimjS4KOxwRkdBlfq+hLk3nSu8vYU0uHBz0deCc8OISEeknAv1GYGbzzazKzKrN7I5u9puZ/TC+/y0zOz/pQcy5E759ACZ+kMaxs5nS9HP+qfJVBl/1zaS/lYhIOgosEZhZNvAgcBVwOvBpMzu9y7CrgLL4z03Aj4OKp66phbU76xmQk80X50wL6m1ERNJOkN8IZgLV7r7e3ZuBpcC1XcZcC/zUY5YDQ80s6bf4rtq0j/e2H+RQSxvNbe1sqG1I9luIiKStIBNBKbAlYbsm/tyJjsHMbjKzlWa2cvfu3ScWxXPfZcaSScyy95md9T7VeZ9mxpJJsdqBiIgEWizu7i4tP4kxuPsiYBFAZWXlMft7NedOVk25mesXL6eltZ3cnCwevXE2Mybq/gEREQg2EdQAiX2dxwHbTmLMKZsxcRiP3jib5ev3MHvKCCUBEZEEQSaCFUCZmU0GtgILgM90GfM4cIuZLQVmAQfcfXsQwcyYOEwJQESkG4ElAndvNbNbgGVANvCwu79rZjfH9y8EngCuBqqBRuCGoOIREZHuBXpDmbs/Qexkn/jcwoTHDnwpyBhERKR3kWsxISIiR1MiEBGJOCUCEZGIUyIQEYk4i9Vr04eZ7QY2neSvjwRqkxhOOtAxR4OOORpO5Zgnuvuo7nakXSI4FWa20t0rw44jlXTM0aBjjoagjllTQyIiEadEICIScVFLBIvCDiAEOuZo0DFHQyDHHKkagYiIHCtq3whERKQLJQIRkYjLyERgZvPNrMrMqs3sjm72m5n9ML7/LTM7P4w4k6kPx3x9/FjfMrNXzOycMOJMpuMdc8K4C8yszcyuS2V8QejLMZvZpWb2hpm9a2YvpDrGZOvDv+0hZvYHM3szfsxp3cXYzB42s11m9k4P+5N//nL3jPoh1vJ6HTAFyAPeBE7vMuZq4I/EVkibDfwl7LhTcMwXAcPij6+KwjEnjHuWWBfc68KOOwV/z0OB94AJ8e3RYcedgmP+B+Du+ONRwF4gL+zYT+GYPwScD7zTw/6kn78y8RvBTKDa3de7ezOwFLi2y5hrgZ96zHJgqJmNSXWgSXTcY3b3V9x9X3xzObHV4NJZX/6eAf4e+DWwK5XBBaQvx/wZ4DfuvhnA3dP9uPtyzA4UmZkBhcQSQWtqw0wed3+R2DH0JOnnr0xMBKXAloTtmvhzJzomnZzo8XyB2CeKdHbcYzazUuBjwEIyQ1/+nsuBYWb2vJmtMrPPpiy6YPTlmH8EnEZsmdu3gVvdvT014YUi6eevQBemCYl181zXa2T7Miad9Pl4zGwOsUTwwUAjCl5fjvl+4HZ3b4t9WEx7fTnmHGAGcDkwEHjVzJa7+5qggwtIX455HvAGcBkwFXjazF5y94NBBxeSpJ+/MjER1ADjE7bHEfukcKJj0kmfjsfMzgYWA1e5+54UxRaUvhxzJbA0ngRGAlebWau7/y41ISZdX/9t17p7A9BgZi8C5wDpmgj6csw3AHd5bAK92sw2ANOB11ITYsol/fyViVNDK4AyM5tsZnnAAuDxLmMeBz4br77PBg64+/ZUB5pExz1mM5sA/Ab4mzT+dJjouMfs7pPdfZK7TwJ+BXwxjZMA9O3f9u+Bi80sx8wKgFnA+ymOM5n6csybiX0DwsyKgQpgfUqjTK2kn78y7huBu7ea2S3AMmJXHDzs7u+a2c3x/QuJXUFyNVANNBL7RJG2+njM3wRGAA/FPyG3ehp3buzjMWeUvhyzu79vZk8CbwHtwGJ37/YyxHTQx7/nfwQeMbO3iU2b3O7uadue2sweAy4FRppZDfAtIBeCO3+pxYSISMRl4tSQiIicACUCEZGIUyIQEYk4JQIRkYhTIhARiTglApE+incwfSPhZ1K80+cBM3vdzN43s2/FxyY+v9rM7gk7fpGeZNx9BCIBOuTu5yY+YWaTgJfc/cNmNgh4w8z+M777yPMDgdfN7Lfu/ufUhixyfPpGIJIk8bYOq4j1u0l8/hCxXjjp3NhQMpgSgUjfDUyYFvpt151mNoJYf/h3uzw/DCgDXkxNmCInRlNDIn13zNRQ3MVm9jqxlg53xVsgXBp//i1ivW/ucvcdKYxVpM+UCERO3Uvu/uGenjezcuDleI3gjVQHJ3I8mhoSCVi82+t3gdvDjkWkO0oEIqmxEPiQmU0OOxCRrtR9VEQk4vSNQEQk4pQIREQiTolARCTilAhERCJOiUBEJOKUCEREIk6JQEQk4v4/XD8cJY186UoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.plot(plt1_fpr,plt1_tpr,marker ='.')\n",
    "_=plt.plot(plt_fpr,plt_tpr,marker ='_')\n",
    "_=plt.title('ROC Curve')\n",
    "_=plt.xlabel('FPR')\n",
    "_=plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** __I used Logistic Regression to solve the classification problem of identiifying the probability of employees getting attrition__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the dataset of cleaned data which is pre-processed\n",
    "2. Using OLS , identify the key features \n",
    "3. Using StratifiedKFold, splitting the data into Train and Test dataset\n",
    "4. HyperParameter Tuning on train dataset to identify the optimal parameters using GridSearchCV and RandomizedSearchCV\n",
    "   Models tried:\n",
    "    1. Logistic Regression\n",
    "    2. Support Vector Machine\n",
    "    3. Random Forest\n",
    "    4. XGBoost Classsifier\n",
    "    __Logistic Regression showed better score than other models with optimal parameters to be used__\n",
    "6. Using SMOTETomek, balanced the dataset as the distribution is (0.84,0.16) for the target variable\n",
    "7. Building the model, used Logistic Regression to fit the train dataset and predicted the values of test dataset\n",
    "8. __HR likes to identify the people who are most likely to quit so they can talk to them and make them stay. So we need to tune the model to    decrease FalseNegative (which is TypeI error)__\n",
    "   Using predict_proba, used the threshold of 70% to increase the Recall score/decrease the TypeI error\n",
    "\n",
    "9. Evaluated the model using evaluation metrics like classification report, confusion matrix, false and true positive rate,\n",
    "   ROC_AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
